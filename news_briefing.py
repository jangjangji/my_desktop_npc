import feedparser
from bs4 import BeautifulSoup
from summarizer import summarize_text

def extract_main_text_from_html(html):
    soup = BeautifulSoup(html, 'html.parser')
    # ZDNetì˜ content:encodedëŠ” <p>, <img>, <br> ë“± í¬í•¨
    paragraphs = soup.find_all("p")
    text = "\n".join(p.get_text(strip=True) for p in paragraphs)
    return text.strip()

def fetch_and_summarize_rss(rss_url, limit=5):
    feed = feedparser.parse(rss_url)
    print(f"ì´ {len(feed.entries)}ê°œ ê¸°ì‚¬ ë°œê²¬ë¨\n")
    result = []

    for entry in feed.entries[:limit]:
        title = entry.title
        link = entry.link
        print(f"ğŸ“° {title} â†’ ìš”ì•½ ì¤‘...")

        html_content = ""
        if 'content' in entry and entry.content:
            html_content = entry.content[0].value
        elif 'summary' in entry:
            html_content = entry.summary

        content = extract_main_text_from_html(html_content)
        if not content:
            print(f"â— ë³¸ë¬¸ ì—†ìŒ, ê±´ë„ˆëœ€\n")
            continue

        try:
            summary = summarize_text(content)
        except Exception as e:
            print(f"â— ìš”ì•½ ì‹¤íŒ¨: {e}\n")
            continue

        result.append(f"ğŸ“° {title}\n{summary}\nğŸ”— {link}\n")

    return "\n".join(result)

if __name__ == "__main__":
    rss_url = "http://feeds.feedburner.com/zdkorea"
    print(fetch_and_summarize_rss(rss_url))

